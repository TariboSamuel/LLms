{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMxXBHqpd8k93ArTqXPQw1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain: Q&A over Documents with OpenAI"
      ],
      "metadata": {
        "id": "RlQ4OhCRxDja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain"
      ],
      "metadata": {
        "id": "3dw0hGAwwzzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import openai\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv()) # read local .env file"
      ],
      "metadata": {
        "id": "3trwz4Mbwzxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install python-dotenv"
      ],
      "metadata": {
        "id": "ZE-2XjqY2LOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain -q"
      ],
      "metadata": {
        "id": "YbZBC0UT255p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "E1oNdy6j3ZeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gsn5vALEwzuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Paste your OpenAI key here and hit enter:\")\n",
        "# user input\n",
        "\n",
        "openai_api_key = os.environ['OPENAI_API_KEY']\n",
        "# setting the api key as an environment variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp80hHxTAzgD",
        "outputId": "2baa6b67-3b21-48b7-c9cc-972a27ae898f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your OpenAI key here and hit enter:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# userdata.get('openai.api_key')"
      ],
      "metadata": {
        "id": "viN-VfV9wzrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI    #importing the openai class from the llm module in the langchain library"
      ],
      "metadata": {
        "id": "XZgeYesRwzo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot"
      ],
      "metadata": {
        "id": "PrkWkt41BikS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, max_tokens=50)  # Specifying the desired maximum token limit\n",
        "text = \"who was the first emperor of france\"\n",
        "print(llm(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da54hwKuwzia",
        "outputId": "c5afbb34-aa49-4b87-8ad9-2b36622c67ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The first emperor of France was Napoleon Bonaparte. He declared himself Emperor of the French in 1804 after serving as First Consul of the French Republic from 1799 to 1804.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q & A Document"
      ],
      "metadata": {
        "id": "MaBVcJE6B32E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from IPython.display import display, Markdown\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "tf6dNqeuwza5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/OutdoorClothingCatalog_1000.csv'\n",
        "loader = CSVLoader(file_path=file)\n",
        "# importing file"
      ],
      "metadata": {
        "id": "t7VM_dUVwzXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "HwLffTWBwzUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install docarray -q"
      ],
      "metadata": {
        "id": "Ja8IsbDjwzMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tiktoken -q"
      ],
      "metadata": {
        "id": "cKkcvIKHEDLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=DocArrayInMemorySearch\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "id": "7dyKiaYnwzJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"Please list all your shirts with sun protection \\\n",
        "in a table in markdown and summarize each one.\""
      ],
      "metadata": {
        "id": "m2FXpEs5DryU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U langchain-openai -q"
      ],
      "metadata": {
        "id": "zNezvXOiKqL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "ZbS6u9Z7x-dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **DocArrayInMemoryVectorStore**\n",
        "DocArrayInMemoryVectorStore is a component within the **DocArray** library, used for storing and managing documents represented as vectors in memory. It specifically handles the aspects related to vector search and retrieval operations.\n",
        "\n",
        "Here's a breakdown of the key concepts:\n",
        "\n",
        "**DocArray:**\n",
        "\n",
        "* An open-source Python library providing tools for efficient document management and manipulation.\n",
        "* Supports various document formats like text, images, code, and more.\n",
        "* Offers functionalities for document representation, retrieval, filtering, and analysis.\n",
        "\n",
        "\n",
        "**Vector Store:**\n",
        "\n",
        "* A mechanism for storing and querying data represented as vectors, which are multi-dimensional numerical arrays capturing information about the data.\n",
        "* Useful for tasks like similarity search, where you want to find documents similar to a given query based on their vector representations.\n",
        "\n",
        "__DocArrayInMemoryVectorStore:__\n",
        "\n",
        "* A specific implementation of a vector store within DocArray.\n",
        "* Stores document vectors directly in memory, making it suitable for small to medium-sized datasets.\n",
        "* Offers fast retrieval and search operations due to in-memory access.\n",
        "* However, it doesn't persist data after program termination, so it's best for temporary tasks or experimentation.\n",
        "\n",
        "__Use Cases:__\n",
        "\n",
        "* Interactive analysis and exploration of datasets with vector representations.\n",
        "* Prototyping and development of applications requiring fast vector search.\n",
        "* Learning about vector search concepts and using DocArray functionalities.\n",
        "\n",
        "__Alternatives:__\n",
        "\n",
        "* DocArray also offers database-backed vector stores like `WeaviateDocumentIndex` and `QdrantDocumentIndex` for persistent storage and scalability with larger datasets.\n",
        "* Other popular vector store options include Faiss, Milvus, and Pinecone.\n",
        "\n",
        "If you'd like to learn more about the specific capabilities of DocArrayInMemoryVectorStore, you can refer to the official documentation: https://docs.docarray.org/user_guide/storing/index_in_memory/\n",
        "\n",
        "Remember, the suitability of DocArrayInMemoryVectorStore depends on your specific needs and dataset size. Consider the mentioned alternatives and their features for more complex or persistent storage requirements."
      ],
      "metadata": {
        "id": "4BtKVoo3IYS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "loader = CSVLoader(file_path=file)"
      ],
      "metadata": {
        "id": "PxwwRsNsDrjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "UJubLtx6wy2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtFF7Y2vwqmo",
        "outputId": "28e38b0d-dba9-4213-eac2-96fe0bf8803f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\", metadata={'source': '/content/OutdoorClothingCatalog_1000.csv', 'row': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "oIX6WK9CH38z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = embeddings.embed_query(\"Hi my name is Samuel\")\n",
        "# this saves the character in memory in vector form so that the computer can understand"
      ],
      "metadata": {
        "id": "SkOfL9RcH-DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YHmjuvHH-Ak",
        "outputId": "0780197b-9432-4de3-89ae-902dbbf5d4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn1xn8WdH996",
        "outputId": "907f7686-1181-458b-9efb-b44b61f4a5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.019195302554069014, 0.010774544123988972, -0.033934777677191, -0.019635851684625075, -0.024708445663176287]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import DocArrayInMemorySearch"
      ],
      "metadata": {
        "id": "ZbXOvPY8zScj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = DocArrayInMemorySearch.from_documents(\n",
        "    docs,\n",
        "    embeddings\n",
        ")\n",
        "# storing in a vectorstore"
      ],
      "metadata": {
        "id": "eCxLJ2HaH963"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.text_splitters import CharacterTextSplitter\n",
        "!pip install langchain -q"
      ],
      "metadata": {
        "id": "J9hTKVVFzckG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain[text_splitters]\n"
      ],
      "metadata": {
        "id": "Qhr_1SEj48Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitters import CharacterTextSplitter\n",
        "\n",
        "print(\"CharacterTextSplitter successfully imported!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "b_NlvIVR48Bl",
        "outputId": "1ee084eb-d539-4606-ad36-b8ce241b412f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.text_splitters'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d50baa1cf0ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CharacterTextSplitter successfully imported!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.text_splitters'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uxpvvpnv478-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.text_splitters import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "-fJKTp3Z3pnh",
        "outputId": "6a52eb02-9fc0-425d-9060-2c53a06daf6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.text_splitters'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7470a4602b9d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCSVLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocArrayInMemorySearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.text_splitters'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()\n",
        "texts = [d.page_content for d in docs]\n",
        "metadatas = [d.metadata for d in docs]\n",
        "text_splitter = CharacterTextSplitter(chunk_overlap=40, chunk_size=1024)\n",
        "db = DocArrayInMemorySearch.from_texts(texts, embeddings, metadatas=metadatas, text_splitter=text_splitter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "YKGkS1wwy-Nt",
        "outputId": "296b93f2-b09d-4c1d-f6ba-241c0dcfc1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CharacterTextSplitter' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-490fadc54509>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_splitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharacterTextSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocArrayInMemorySearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_splitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_splitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CharacterTextSplitter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature = 0.0, model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "JKgHCRDVH9zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have defined your embeddings and docs\n",
        "model_type = \"gpt-3.5-turbo\"  # Example model type\n",
        "\n",
        "# Create the DocArrayInMemorySearch object with model type\n",
        "db = DocArrayInMemorySearch.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    model_type=\"gpt-3.5-turbo\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "k8iLvGwPH9uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yYN1mUvqH9rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fc3qcGRYH9oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWjyn5EWH9mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain QA\n",
        "\n",
        "All code comes from LangChain docs."
      ],
      "metadata": {
        "id": "GrCL3HsQjot3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain openai chromadb tiktoken pypdf"
      ],
      "metadata": {
        "id": "648pANDdgQVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "_hrw8cq_pyKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "VYyMbNX4nznq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "31lbhU1egQHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "# load document\n",
        "loader = PyPDFLoader(\"/example.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "### For multiple documents\n",
        "# loaders = [....]\n",
        "# documents = []\n",
        "# for loader in loaders:\n",
        "#     documents.extend(loader.load())\n",
        "\n",
        "chain = load_qa_chain(llm=OpenAI(), chain_type=\"map_reduce\")\n",
        "query = \"what is the total number of AI publications?\"\n",
        "chain.run(input_documents=documents, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "klm1N-Y9gPug",
        "outputId": "4b920598-9a12-4ada-e63e-6776a1b21184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ff584f2bf499>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     documents.extend(loader.load())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_qa_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map_reduce\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"what is the total number of AI publications?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mobject_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__dict__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
          ]
        }
      ]
    }
  ]
}